#!/usr/bin/env python3
"""
2025ë…„ 12ì›” ë‰´ìŠ¤ ë°±í•„ ìŠ¤í¬ë¦½íŠ¸

12ì›” 1ì¼ë¶€í„° 7ì¼ê¹Œì§€ ë‰´ìŠ¤ë¥¼ í´ë¦¬í•‘í•˜ê³  ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import sys
from pathlib import Path
from datetime import datetime, date, timedelta

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

from loguru import logger
from utils.config import get_settings
from utils.logger import setup_logger
from collector import NewsCollector
from analyzer import NewsAnalyzer
from publisher import NotionPublisher
from storage import NewsDatabase
from analyzer.gemini_client import GeminiAnalyzer


def run_clipper_for_date(target_date: date, period: str, hours: int, settings, publisher, collector, analyzer, database, gemini):
    """íŠ¹ì • ë‚ ì§œì™€ ê¸°ê°„ì— ëŒ€í•´ ë‰´ìŠ¤ í´ë¦¬í•‘ ì‹¤í–‰"""
    
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸ“… {target_date} {period} ë‰´ìŠ¤ í´ë¦¬í•‘ ì‹œì‘")
    logger.info(f"{'='*60}")
    
    # í‚¤ì›Œë“œ ì¡°í•© ë¡œë“œ
    keyword_combinations = settings.get_keyword_combinations()
    config = settings.load_config()
    
    try:
        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        when = f"{hours}h"
        logger.info(f"ğŸ“° Step 1: ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (ìµœê·¼ {hours}ì‹œê°„)")
        
        articles = collector.collect_all(
            keyword_combinations=keyword_combinations,
            max_results_per_combo=20,
            use_naver=bool(settings.naver_client_id),
            when=when
        )
        
        if not articles:
            logger.warning("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info(f"ğŸ“¥ ìˆ˜ì§‘ ì™„ë£Œ: {len(articles)}ê±´")
        
        # 1.5. ì–¸ë¡ ì‚¬ í•„í„°ë§
        logger.info("ğŸ“° Step 1.5: ì–¸ë¡ ì‚¬ í•„í„°ë§ ì¤‘...")
        news_sources = config.get("news_sources", {})
        allowed_domains = []
        
        for media in news_sources.get("priority_media", []):
            allowed_domains.append(media.get("domain", ""))
        for media in news_sources.get("national_media", []):
            allowed_domains.append(media.get("domain", ""))
        
        if allowed_domains:
            original_count = len(articles)
            articles = [
                article for article in articles
                if any(domain in (article.url or "") for domain in allowed_domains)
            ]
            logger.info(f"ğŸ¢ ì–¸ë¡ ì‚¬ í•„í„°ë§: {original_count}ê±´ â†’ {len(articles)}ê±´")
        
        if not articles:
            logger.warning("ì§€ì •ëœ ì–¸ë¡ ì‚¬ì˜ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # 2. ì¤‘ë³µ ì œê±° (ë°±í•„ì´ë¯€ë¡œ ìŠ¤í‚µí•˜ê±°ë‚˜ ëŠìŠ¨í•˜ê²Œ)
        logger.info("ğŸ”„ Step 2: ì¤‘ë³µ í™•ì¸ ì¤‘...")
        # articles = database.filter_duplicates(articles)  # ë°±í•„ ì‹œ ìŠ¤í‚µ
        logger.info(f"âœ¨ ì²˜ë¦¬í•  ë‰´ìŠ¤: {len(articles)}ê±´")
        
        # 3. AI ë¶„ì„ ë° í•„í„°ë§
        logger.info("ğŸ¤– Step 3: AI ë¶„ì„ ì¤‘...")
        passed_articles, filtered_articles = analyzer.analyze_and_filter(
            articles=articles,
            summarize=True
        )
        
        if not passed_articles:
            logger.info("ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ì¤‘ìš”ë„ìˆœ ì •ë ¬
        passed_articles = analyzer.sort_by_importance(passed_articles)
        logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: ê´€ë ¨ ë‰´ìŠ¤ {len(passed_articles)}ê±´")
        
        # 3.5. ì¸ì‚¬ì´íŠ¸ ìƒì„±
        logger.info("ğŸ’¡ Step 3.5: ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
        insight = gemini.generate_daily_insight(passed_articles)
        logger.info(f"ğŸ’¡ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {insight.get('headline', '')[:50]}...")
        
        # 4. ë…¸ì…˜ ë°œí–‰
        logger.info("ğŸ“¤ Step 4: ë…¸ì…˜ ë°œí–‰ ì¤‘...")
        results = publisher.publish_articles(
            articles=passed_articles,
            create_summary=True,
            insight=insight,
            period=period,
            target_date=target_date
        )
        
        logger.info(f"ğŸ“ ë°œí–‰ ì™„ë£Œ: ì„±ê³µ {len(results['success'])}ê±´")
        
        # 5. DB ì €ì¥
        logger.info("ğŸ’¾ Step 5: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
        database.save_articles(passed_articles)
        
        return results
        
    except Exception as e:
        logger.exception(f"âŒ {target_date} {period} í´ë¦¬í•‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # ì„¤ì • ë¡œë“œ
    settings = get_settings()
    
    # ë¡œê±° ì„¤ì •
    setup_logger(
        log_level=settings.log_level,
        log_file=Path("logs") / f"backfill_december_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    )
    
    logger.info("=" * 60)
    logger.info("ğŸš€ 2025ë…„ 12ì›” ë‰´ìŠ¤ ë°±í•„ ì‹œì‘")
    logger.info("=" * 60)
    
    # ì„¤ì • ê²€ì¦
    if not settings.notion_database_id:
        logger.error("âŒ NOTION_DATABASE_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        sys.exit(1)
    
    logger.info(f"ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ ID: {settings.notion_database_id[:8]}...")
    
    # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    collector = NewsCollector(
        naver_client_id=settings.naver_client_id,
        naver_client_secret=settings.naver_client_secret
    )
    
    analyzer = NewsAnalyzer(
        api_key=settings.google_api_key,
        relevance_threshold=settings.relevance_threshold
    )
    
    # ê¸°ì¡´ DB ì‚¬ìš© (ì›”ë³„ DB ìƒì„± ë¬¸ì œë¡œ ì¸í•´ ì„ì‹œë¡œ ê¸°ì¡´ DB ì‚¬ìš©)
    # ì›”ë³„ DB ê¸°ëŠ¥ì€ ë…¸ì…˜ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ DB ìƒì„± í›„ ì‚¬ìš© ê¶Œì¥
    publisher = NotionPublisher(
        api_key=settings.notion_api_key,
        database_id=settings.notion_database_id
    )
    
    database = NewsDatabase(db_path=settings.db_path)
    
    gemini = GeminiAnalyzer(
        api_key=settings.google_api_key,
        is_paid_plan=True
    )
    
    # 12ì›” 1ì¼ë¶€í„° 7ì¼ê¹Œì§€ í´ë¦¬í•‘
    start_date = date(2025, 12, 1)
    end_date = date(2025, 12, 7)
    
    current_date = start_date
    while current_date <= end_date:
        # ì˜¤ì „ í´ë¦¬í•‘ (16ì‹œê°„)
        run_clipper_for_date(
            target_date=current_date,
            period="ì˜¤ì „",
            hours=16,
            settings=settings,
            publisher=publisher,
            collector=collector,
            analyzer=analyzer,
            database=database,
            gemini=gemini
        )
        
        # ì˜¤í›„ í´ë¦¬í•‘ (8ì‹œê°„)
        run_clipper_for_date(
            target_date=current_date,
            period="ì˜¤í›„",
            hours=8,
            settings=settings,
            publisher=publisher,
            collector=collector,
            analyzer=analyzer,
            database=database,
            gemini=gemini
        )
        
        current_date += timedelta(days=1)
        logger.info(f"\nâ³ ë‹¤ìŒ ë‚ ì§œë¡œ ì´ë™: {current_date}")
    
    logger.info("\n" + "=" * 60)
    logger.info("âœ… 2025ë…„ 12ì›” ë‰´ìŠ¤ ë°±í•„ ì™„ë£Œ!")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()

