"""
ë‰´ìŠ¤ í´ë¦¬í•‘ ìë™í™” ì„œë¹„ìŠ¤ ë©”ì¸ ëª¨ë“ˆ

ì •ì˜ë‹¹ ê²½ë‚¨ë„ë‹¹ ë‰´ìŠ¤ í´ë¦¬í•‘ ìë™í™” ì„œë¹„ìŠ¤
- Google News RSSë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
- Claude APIë¡œ ë¶„ì„ ë° ìš”ì•½
- ë…¸ì…˜ì— ìë™ ë°œí–‰
"""

import sys
from datetime import datetime
from pathlib import Path

from loguru import logger

import sys
from pathlib import Path

# src ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€
src_dir = Path(__file__).parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

from utils.config import get_settings
from utils.logger import setup_logger
from collector import NewsCollector
from analyzer import NewsAnalyzer
from publisher import NotionPublisher
from storage import NewsDatabase


def run_news_clipper():
    """ë‰´ìŠ¤ í´ë¦¬í•‘ ì‹¤í–‰"""
    
    # ì„¤ì • ë¡œë“œ
    settings = get_settings()
    
    # ë¡œê±° ì„¤ì •
    setup_logger(
        log_level=settings.log_level,
        log_file=Path("logs") / f"clipper_{datetime.now().strftime('%Y%m%d')}.log"
    )
    
    logger.info("=" * 60)
    logger.info("ğŸš€ ë‰´ìŠ¤ í´ë¦¬í•‘ ì„œë¹„ìŠ¤ ì‹œì‘")
    logger.info(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    # ì„¤ì • ê²€ì¦
    if not settings.google_api_key:
        logger.error("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        sys.exit(1)
    
    # ì›”ë³„ DB ì‚¬ìš© ì—¬ë¶€ í™•ì¸
    use_monthly = settings.use_monthly_db()
    parent_page_id = settings.get_parent_page_id()
    
    if use_monthly and not parent_page_id:
        logger.error("âŒ ì›”ë³„ DBë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ NOTION_PARENT_PAGE_IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        sys.exit(1)
    
    if not use_monthly and (not settings.notion_api_key or not settings.notion_database_id):
        logger.error("âŒ NOTION_API_KEY ë˜ëŠ” NOTION_DATABASE_IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        sys.exit(1)
    
    # í‚¤ì›Œë“œ ì¡°í•© ë¡œë“œ
    keyword_combinations = settings.get_keyword_combinations()
    if not keyword_combinations:
        logger.error("âŒ í‚¤ì›Œë“œ ì¡°í•©ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        sys.exit(1)
    
    logger.info(f"ğŸ“ í‚¤ì›Œë“œ ì¡°í•© {len(keyword_combinations)}ê°œ ë¡œë“œë¨")
    
    # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    collector = NewsCollector(
        naver_client_id=settings.naver_client_id,
        naver_client_secret=settings.naver_client_secret
    )
    
    analyzer = NewsAnalyzer(
        api_key=settings.google_api_key,
        relevance_threshold=settings.relevance_threshold
    )
    
    # NotionPublisher ì´ˆê¸°í™” (ì›”ë³„ DB ë˜ëŠ” ê¸°ì¡´ DB)
    if use_monthly and parent_page_id:
        logger.info(f"ğŸ“… ì›”ë³„ DB ëª¨ë“œ í™œì„±í™” (ìƒìœ„ í˜ì´ì§€: {parent_page_id[:8]}...)")
        publisher = NotionPublisher(
            api_key=settings.notion_api_key,
            parent_page_id=parent_page_id
        )
    else:
        publisher = NotionPublisher(
            api_key=settings.notion_api_key,
            database_id=settings.notion_database_id
        )
    
    database = NewsDatabase(db_path=settings.db_path)
    
    try:
        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        # ì‹œê°„ëŒ€ì— ë”°ë¥¸ ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì •
        config = settings.load_config()
        schedule_config = config.get("schedule", {})
        current_hour = datetime.now().hour
        
        # ì˜¤ì „ 10ì‹œ ì‹¤í–‰: 16ì‹œê°„, ì˜¤í›„ 18ì‹œ ì‹¤í–‰: 8ì‹œê°„
        if current_hour < 14:  # ì˜¤ì „~ì˜¤í›„ 2ì‹œ ì´ì „
            hours = schedule_config.get("morning_hours", 16)
        else:  # ì˜¤í›„ 2ì‹œ ì´í›„
            hours = schedule_config.get("evening_hours", 8)
        
        when = f"{hours}h"
        logger.info(f"ğŸ“° Step 1: ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (ìµœê·¼ {hours}ì‹œê°„)")
        
        articles = collector.collect_all(
            keyword_combinations=keyword_combinations,
            max_results_per_combo=20,  # ìœ ë£Œ í”Œëœ: ì¡°í•©ë‹¹ 20ê°œ
            use_naver=bool(settings.naver_client_id),
            when=when
        )
        
        if not articles:
            logger.warning("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info(f"ğŸ“¥ ìˆ˜ì§‘ ì™„ë£Œ: {len(articles)}ê±´")
        
        # 1.5. ë°œí–‰ ì‹œê°„ í•„í„°ë§ (ì§€ì •ëœ ì‹œê°„ ë‚´ ë‰´ìŠ¤ë§Œ)
        from datetime import timedelta
        cutoff_time = datetime.now() - timedelta(hours=hours)
        original_count = len(articles)
        
        filtered_by_time = []
        no_date_count = 0
        for article in articles:
            if article.published_at:
                # timezone-aware datetime ì²˜ë¦¬
                pub_time = article.published_at
                if pub_time.tzinfo is not None:
                    # timezone ì •ë³´ ì œê±°í•˜ì—¬ ë¹„êµ
                    pub_time = pub_time.replace(tzinfo=None)
                
                if pub_time >= cutoff_time:
                    filtered_by_time.append(article)
            else:
                # ë°œí–‰ì¼ì´ ì—†ëŠ” ê²½ìš° ì œì™¸ (ì˜¤ë˜ëœ ë‰´ìŠ¤ì¼ ê°€ëŠ¥ì„±)
                no_date_count += 1
        
        articles = filtered_by_time
        logger.info(f"â° ì‹œê°„ í•„í„°ë§: {original_count}ê±´ â†’ {len(articles)}ê±´ (ìµœê·¼ {hours}ì‹œê°„, ë‚ ì§œì—†ìŒ {no_date_count}ê±´ ì œì™¸)")
        
        if not articles:
            logger.warning(f"ìµœê·¼ {hours}ì‹œê°„ ë‚´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # 1.6. ì–¸ë¡ ì‚¬ í•„í„°ë§
        logger.info("ğŸ“° Step 1.6: ì–¸ë¡ ì‚¬ í•„í„°ë§ ì¤‘...")
        news_sources = config.get("news_sources", {})
        allowed_domains = []
        
        # priority_mediaì™€ national_mediaì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ
        for media in news_sources.get("priority_media", []):
            allowed_domains.append(media.get("domain", ""))
        for media in news_sources.get("national_media", []):
            allowed_domains.append(media.get("domain", ""))
        
        if allowed_domains:
            original_count = len(articles)
            articles = [
                article for article in articles
                if any(domain in (article.url or "") for domain in allowed_domains)
            ]
            logger.info(f"ğŸ¢ ì–¸ë¡ ì‚¬ í•„í„°ë§: {original_count}ê±´ â†’ {len(articles)}ê±´")
        
        if not articles:
            logger.warning("ì§€ì •ëœ ì–¸ë¡ ì‚¬ì˜ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # 2. ì¤‘ë³µ ì œê±°
        logger.info("ğŸ”„ Step 2: ì¤‘ë³µ ì œê±° ì¤‘...")
        articles = database.filter_duplicates(articles)
        
        if not articles:
            logger.info("ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info(f"âœ¨ ì‹ ê·œ ë‰´ìŠ¤: {len(articles)}ê±´")
        
        # 3. AI ë¶„ì„ ë° í•„í„°ë§
        logger.info("ğŸ¤– Step 3: AI ë¶„ì„ ì¤‘...")
        passed_articles, filtered_articles = analyzer.analyze_and_filter(
            articles=articles,
            summarize=True
        )
        
        if not passed_articles:
            logger.info("ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            # í•„í„°ë§ëœ ê¸°ì‚¬ë„ DBì— ì €ì¥ (ì¤‘ë³µ ë°©ì§€ìš©)
            database.save_articles(filtered_articles)
            return
        
        # ì¤‘ìš”ë„ìˆœ ì •ë ¬
        passed_articles = analyzer.sort_by_importance(passed_articles)
        
        logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: ê´€ë ¨ ë‰´ìŠ¤ {len(passed_articles)}ê±´")
        
        # 3.5. ì¸ì‚¬ì´íŠ¸ ìƒì„±
        logger.info("ğŸ’¡ Step 3.5: ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘...")
        from analyzer.gemini_client import GeminiAnalyzer
        gemini = GeminiAnalyzer(
            api_key=settings.google_api_key,
            is_paid_plan=True
        )
        insight = gemini.generate_daily_insight(passed_articles)
        logger.info(f"ğŸ’¡ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {insight.get('headline', '')[:50]}...")
        
        # 4. ë…¸ì…˜ ë°œí–‰
        logger.info("ğŸ“¤ Step 4: ë…¸ì…˜ ë°œí–‰ ì¤‘...")
        
        # ì˜¤ì „/ì˜¤í›„ êµ¬ë¶„ (14ì‹œ ê¸°ì¤€)
        period = "ì˜¤ì „" if current_hour < 14 else "ì˜¤í›„"
        
        results = publisher.publish_articles(
            articles=passed_articles,
            create_summary=True,
            insight=insight,
            period=period
        )
        
        logger.info(f"ğŸ“ ë°œí–‰ ì™„ë£Œ: ì„±ê³µ {len(results['success'])}ê±´")
        
        # 5. DB ì €ì¥
        logger.info("ğŸ’¾ Step 5: ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
        database.save_articles(passed_articles)
        database.save_articles(filtered_articles)
        
        # ì˜¤ë˜ëœ ë ˆì½”ë“œ ì •ë¦¬
        database.cleanup_old_records(days=30)
        
        # í†µê³„ ì¶œë ¥
        stats = database.get_stats()
        logger.info(f"ğŸ“Š DB í†µê³„: ì „ì²´ {stats['total']}ê±´, ì˜¤ëŠ˜ {stats['today']}ê±´")
        
    except Exception as e:
        logger.exception(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
    
    logger.info("=" * 60)
    logger.info("âœ… ë‰´ìŠ¤ í´ë¦¬í•‘ ì™„ë£Œ")
    logger.info("=" * 60)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    run_news_clipper()


if __name__ == "__main__":
    main()

